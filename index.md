#aws-kubernetes-ansible-vagrant

#Prerequisites
Hardware:

A Linux machine (This tutorial uses Ubuntu 20.04) with at least 8 GB of RAM and 15 GB.

lsb_release -a
Distributor ID: Ubuntu
Description: Ubuntu 20.04 LTS
Release: 20.04
Codename: focal

#Software:

Vagrant 2.2.9
wget https://releases.hashicorp.com/vagrant/2.2.9/vagrant_2.2.9_x86_64.deb
sudo apt install ./vagrant_2.2.9_x86_64.deb
VirtualBox 6.1.6 or above
sudo apt install virtualbox
Ansible 2.9.6
sudo apt-add-repository --yes --update ppa:ansible/ansible
sudo apt install ansible

#File structure

#The code used to create a Kubernetes Cluster with Vagrant and Ansible consists of:

.vagrant / : hidden directory used by Vagrant to manage resources. Includes the generated vagrant_ansible_inventory inventory that Ansible will use to identify each VM's membership in the master or worker / node group and install the correct roles.
add_packages : Ansible playbook to install / remove software packages in Ubuntu using APT.
k8s /
common / : installs the necessary packages for Kubernetes (delegating to add_packages ) and performs the common configuration for the master and nodes.
master / : Ansible playbook to configure the Kubernetes master, use the common playbook for common components.
node / : Ansible playbook to configure Kubernetes nodes, use common playbook for common components.
ditwl-k8s-01-join-command : this file is generated by Kubernetes after installing the master and contains the command necessary to join the nodes to the cluster together with the token that allows it.
k8s.yml : Ansible playbook that makes use of Ansible roles for Kubernetes. Will be executed by Vagrant Provisioner
Vagrantfile : contains the definition of the virtual machines (CPU, memory, network), the provisioner configuration (Ansible and properties).
Networking in Kubernetes over VirtualBox
The biggest difficulty in using Kubernetes on VirtualBox virtual machines is setting up the network environment.

The network of the Kubernetes cluster and the Virtualbox machines will be made up of at least 3 networks shown in the following network diagram:

LAN, NAT, HOST Only and Tunnel Kubernetes networks
Kubernetes Network Overview
Kubernetes External Network in VirtualBox

The VirtualBox HOST ONLY network is the network used to access the Kubernetes master and nodes from outside of VirtualBox. We will consider it as the equivalent of a public network within our development environment.

#The diagram is shown in green with connections to each virtual machine and to the VirtualBox router in its virtual vboxnet interface:

K8S-M-1 at eth1: 192.168.50.11
K8S-N-1 at eth1: 192.168.50.12
K8S-N-2 at eth1: 192.168.50.13
vboxnet0 virtual iface: 192.168.50.1
VirtualBox creates the necessary paths and the vboxnet0 interface:

$ route
Kernel IP routing table
Destination Gateway Genmask Flags Metric Ref Use Iface
default _gateway         0 . 0 . 0 . 0          UG     100 0 0 enx106530cde22a            
link-local       0 . 0 . 0 . 0 255,255 . 0 . 0      U      1000 0 0 enx106530cde22a                    
192.168 . 50 . 0 0 . 0 . 0 . 0 255,255 . 255 . 0    U      0 0 0 vboxnet0                           
192.168 . 100 . 0 0 . 0 . 0 . 0 255,255 . 255 . 0    U      100 0 0 enx106530cde22a                        

Applications published through a Kubernetes NodePort will be available on the IPs assigned to the Kubernetes virtual machines within the VirtualBox HOST ONLY network

For example, to access an application published on NodePort 30000 the following URLs will be used from outside the Kubernetes cluster:

http://192.168.50.11:30000/
http://192.168.50.12:30000/
http://192.168.50.13:30000/
See the tutorial how to publish an application outside the Kubernetes cluster.

It is also possible to use these IPs to access the nodes and the Kubernetes master via SSH:

$ ssh vagrant @ 192.168 . 50 . eleven
vagrant @ 192.168 . 50 . 11 's password: vagrant
Welcome to Ubuntu 18.04 . 1 LTS ( GNU / Linux 4.15 . 0 - 29 -generic x86_64 )  
...
Last login: Mon Apr 22 16 : 45 : 17 2019 from 10.0 . 2 . two  
VirtualBox NAT network
The NAT network interface, with the same IP (10.0.2.15) for all virtual machines in the Kubernetes cluster, is assigned to the first network interface of each VirtualBox machine. It is used to access from the Kubernetes cluster machines to the outside (LAN and Internet).

The diagram is shown in yellow with connections to each machine in the cluster and to a NAT router that connects to the LAN and the Internet.

This connection is the one used by Ansible (running on each node) during cluster setup to download the necessary packages from the Internet. As it is a NAT interface, incoming connections are not allowed by default.

Kubernetes POD Network
Internal connections between Kubernetes PODs use a tunnel network with IPs in the 192.168.112.0/20 range (configured in the Ansible playbook). In the diagram it is shown in orange color connecting each Kubernetes machine using tunnel interfaces.

Kubernetes assigns IPs from the POD network to each POD created. POD IPs are not accessible from outside the Kubernetes cluster and are ephemeral (they will change when a POD is created or destroyed).

Kubernetes Cluster Network (Cluster-IP)
The Kubernetes cluster network is a network that uses a private range of IPs and is intended to be used within the Kubernetes cluster, giving each Kubernetes service a dedicated IP. In the diagram it is shown in purple.

The following listing shows services running on Kubernetes and their assigned CLUSTER-IP:

$ kubectl get all
NAME READY STATUS RESTARTS AGE
pod / nginx-deployment-d7b95894f-2hpjk    1 / 1      Running    0           5m47s
pod / nginx-deployment-d7b95894f-49lrh    1 / 1      Running    0           5m47s
pod / nginx-deployment-d7b95894f-wl497    1 / 1      Running    0           5m47s
NAME TYPE CLUSTER-IP EXTERNAL-IP    PORT ( S )           AGE
service / kubernetes ClusterIP       10.96 . 0 . 1 < none > 443 / TCP 137m              
service / nginx-service-np NodePort        10,103 . 75 . 9 < none > 8082 : 30000 / TCP 5m47s            
NAME READY UP-TO-DATE AVAILABLE AGE
deployment. my / nginx-deployment    3 / 3 3 3            5m47s                 
NAME DESIRED CURRENT READY AGE
replicaset. apps / nginx-deployment-d7b95894f    3 3 3        5m47s                  
It is not possible to access the IPs of the CLUSTER-IP range from outside the cluster, so it is necessary to create a NodePort (in the case of a cluster on Cloud, a native Load Balancer of the IaaS provider is used) to publish applications outside the cluster. A NodePort uses external Kubernetes IPs (External Kubernetes network in VirtualBox)

See “ Publish an Application outside Kubernetes Cluster ” for an explanation of how to publish a Kubernetes application.

#Vagrantfile
The Vagrantfile file defines the hardware configuration of the virtual machines that will be created by Vagrant and executed in VirtualBox. In addition, the Ansible playbook that will be run to provision them is defined.

IMAGE_NAME = "bento / ubuntu-20.04"
K8S_NAME = "ditwl-k8s-01"
MASTERS_NUM = 1
MASTERS_CPU = 2
MASTERS_MEM = 2048
NODES_NUM = 3
NODES_CPU = 4
NODES_MEM = 2048
IP_BASE = "192.168.50."
VAGRANT_DISABLE_VBOXSYMLINKCREATE = 1
Vagrant. configure ( "2" ) do | config |
    config. ssh . insert_key = false
    ( 1. .MASTERS_NUM ) . each do | i |       
        config. vm . define "k8s-m - # {i}" do | master |  
            master. vm . box = IMAGE_NAME
            master. vm . network "private_network" , ip: "# {IP_BASE} # {i + 10}"
            master. vm . hostname = "k8s-m - # {i}"
            master. vm . provider "virtualbox" do | v |  
                v. memory = MASTERS_MEM
                v. cpus = MASTERS_CPU
            end            
            master. vm . provision "ansible" do | ansible |  
                ansible. playbook = "roles / k8s.yml"
                #Redefine defaults
                ansible. extra_vars = {
                    k8s_cluster_name: K8S_NAME,                    
                    k8s_master_admin_user:   "vagrant" ,
                    k8s_master_admin_group: "vagrant" ,
                    k8s_master_apiserver_advertise_address: "# {IP_BASE} # {i + 10}" ,
                    k8s_master_node_name: "k8s-m - # {i}" ,
                    k8s_node_public_ip: "# {IP_BASE} # {i + 10}"
                }                
            end
        end
    end
    ( 1. .NODES_NUM ) . each do | j |
        config. vm . define "k8s-n - # {j}" do | node |  
            do not give. vm . box = IMAGE_NAME
            do not give. vm . network "private_network" , ip: "# {IP_BASE} # {j + 10 + MASTERS_NUM}"
            do not give. vm . hostname = "k8s-n - # {j}"
            do not give. vm . provider "virtualbox" do | v |  
                v. memory = NODES_MEM
                v. cpus = NODES_CPU
            end             
            do not give. vm . provision "ansible" do | ansible |  
                ansible. playbook = "roles / k8s.yml"                   
                #Redefine defaults
                ansible. extra_vars = {
                    k8s_cluster_name: K8S_NAME,
                    k8s_node_admin_user:   "vagrant" ,
                    k8s_node_admin_group: "vagrant" ,
                    k8s_node_public_ip: "# {IP_BASE} # {j + 10 + MASTERS_NUM}"
                }
            end
        end
    end
end

#Kubernetes nodes features:

Node	characteristics	Value
K8S Master	CPU	2 cores
RAM	2 GB
Worker 1… N	CPU	4 cores
RAM	2 GB
Lines 1 through 7 define the properties of the Kubernetes cluster:

#IMAGE_NAME : is the box (virtual machine) that Vagrant will download and use to create the cluster machines. We will use a machine identified as "bento / ubuntu-18.04", which corresponds to a minimal installation of Ubuntu 18.04 packaged by the Bento project.
#K8S_NAME : name that the cluster will have and that will be used to identify the command to join nodes to the master. In our example it is “ditwl-k8s-01”, an acronym for Demo IT Wonder Lab Kubernetes (k8s) and 01, the cluster number.
#MASTERS_NUM : number of master nodes, it is used to create a cluster with high availability on the master nodes. It is not implemented in the Ansible code so currently the maximum number of teachers is 1.
#MASTERS_MEM / NODES_MEM - Amount of memory in megabytes for each Kubernetes master / node.
#MASTERS_CPU / NODOS_CPU : number of CPUs available for each master / node.
#NODES_NUM = Number of Kubernetes worker nodes. They are the nodes that run the PODs through containers, we will create 2 nodes.
#IP_BASE = First octets of the IP address that we will use to define the network Kubernetes external network in VirtualBox, that is, the external interfaces of the VirtualBox machines, in the example they will be assigned:
192.168.50.1 for the vboxnet0
192.168.50.11 for k8s-m-1 (Kubernetes master node 1)
192.168.50.12 for k8s-n-1 (Kubernetes worker node 1)
192.168.50.13 for k8s-n-2 (Kubernetes worker node 2)
Lines 12 to 15 configure the memory and CPU of the machines, the master is created between lines 17 and 40, using a loop to create MASTERS_NUM machines with the following characteristics:

The name of the machines is composed using the expression "k8s-m - # {i}" that identifies the machine as a member of the Kubernetes cluster (k8s), in the role of master (m) and in position # {i} . The value of i increases with each iteration of the loop.

The Ansible provisioner will run with the playbook "roles / k8s.yml"

Extra Ansible variables are defined to modify the default values ​​assigned in Ansible playbooks.

k8s_cluster_name : K8S_NAME
k8s_master_admin_user : "vagrant"
k8s_master_admin_group : "vagrant"
k8s_master_apiserver_advertise_address : "# {IP_BASE} # {i + 10}"
k8s_master_node_name : "k8s-m - # {i}"
Kubernetes worker nodes are created between lines 42 and 64 using code similar to that of the masters.

The name of the nodes will be created using the expression "k8s-n - # {j}" that identifies the machine as belonging to the cluster of k8s, as node "n" and with a number (using the loop variable j)

#Ansible
Playbook k8s.yml

The playbook run by Vagrant's Ansible provisioner, Selects the hosts using a wildcard pattern (k8s-m- * and k8s-n- *) that allows to differentiate between master and nodes.

- hosts : k8s-m- *
  become : yes
  roles :
    - { role : k8s / master }   
- hosts : k8s-n- *
  become : yes
  roles :
    - { role : k8s / node }   
k8s / master
The Ansible k8s / master playbook creates the Kubernetes masters node using the following default settings that can be overridden in the Vagrantfile file (see Vagrantfile Ansible extra vars).

k8s_master_admin_user:   "ubuntu"
k8s_master_admin_group: "ubuntu"
k8s_master_node_name: "k8s-m"
k8s_cluster_name:      "k8s-cluster"
k8s_master_apiserver_advertise_address: "192.168.101.100"
k8s_master_pod_network_cidr: "192.168.112.0/20"
Being a very small cluster, the range for the PODs network has been modified, changing it from 192.168.0.0/16 to 192.168.112.0/20 (192.168.112.0 - 192.168.127.255).

It can be modified both in the default configuration of the Ansible role or in the Vagrantfile file as an extra variable.

The role requires the installation of some additional packages that are common to Kubernetes master and worker nodes. There is a specific role for each task, and the meta folder is used to list dependencies of the role and the variables of those dependencies.

Detail of the role dependencies for the Kubernetes master in Ansible. It is indicated that it depends on the previous execution of the k8s / common role and the value of the role variables is indicated:

dependencies:
  - { role: k8s / common,
      k8s_common_admin_user: "{{k8s_master_admin_user}}" ,
      k8s_common_admin_group: "{{k8s_master_admin_group}}"
    }
Once the dependencies are resolved, the playbook installed by the master is executed:

#https: //docs.projectcalico.org/v3.6/getting-started/kubernetes/
- name: Configure kubectl
  command: kubeadm init --apiserver-advertise-address = "{{k8s_master_apiserver_advertise_address}}" --apiserver-cert-extra-sans = "{{k8s_master_apiserver_advertise_address}}" --node-name = "{{k8s_master_node_name}}" - -pod-network-cidr = "{{k8s_master_pod_network_cidr}}"
  args:
    creates: / etc / kubernetes / manifests / kube-apiserver. yaml
- name: Create .kube dir for {{ k8s_master_admin_user }} user
  file:
      path: "/ home / {{k8s_master_admin_user}} /. kube"
      state: directory
- name: Copy kube config to {{ k8s_master_admin_user }} home .kube dir
  copy:
    src: / etc / kubernetes / admin. conf
    dest: / home / {{ k8s_master_admin_user }} /.kube/config
    remote_src: yes
    owner: "{{k8s_master_admin_user}}"
    group: "{{k8s_master_admin_group}}"
    mode: 0660
#Rewrite calico replacing defaults
#https: //docs.projectcalico.org/v3.9/getting-started/kubernetes/installation/calico
- name: Rewrite calico. yaml
  template:
     src: calico / 3.9 / calico. yaml
     dest: / home / {{ k8s_master_admin_user }} / calico. yaml
- name: Install Calico ( using Kubernetes API datastore )
  become: false
  command: kubectl apply -f / home / {{ k8s_master_admin_user }} / calico. yaml
# Step 2.6 from https://kubernetes.io/blog/2019/03/15/kubernetes-setup-using-ansible-and-vagrant/
- name: Generate join command
  command: kubeadm token create --print-join-command
  register: join_command
- name: Copy join command for {{ k8s_cluster_name }} cluster to local file
  become: false
  local_action: copy content = "{{join_command.stdout_lines [0]}}" dest = "./ {{k8s_cluster_name}} - join-command"
k8s / node
Each worker node must be added as a member of the cluster, for which the command and token generated when installing the master is used.

The join command is kubeadm join and the parameters are the IP and port of the API (api-server-endpoint) located in the master, the token and a hash to validate the public key of the CA (certificate authority) of the cluster.

kubeadm join 192.168 . 50 . 11 : 6443 --token lmnbkq. 80h4j8ez0vfktytw --discovery-token-ca-cert-hash sha256: 54bbeb6b1a519700ae1f2e53c6f420vd8d4fe2d47ab4dbd7ce1a7f62c457f68a1
The playbook to install the nodes is very short, it has a dependency with the k8s / common playbook to set the managed user and group.

dependencies:
  - { role: k8s / common,
      k8s_common_admin_user: "{{k8s_node_admin_user}}" ,
      k8s_common_admin_group: "{{k8s_node_admin_group}}"
    }
Specific tasks to install Kubernetes nodes with Ansible:

- name: Copy the join command to {{ k8s_cluster_name }} cluster
  copy:
    src: "./ {{k8s_cluster_name}} - join-command"
    dest: / home / {{ k8s_node_admin_user }} / {{ k8s_cluster_name }} -join-command
    owner: "{{k8s_node_admin_user}}"
    group: "{{k8s_node_admin_group}}"
    mode: 0760  
- name: Join the node to cluster {{ k8s_cluster_name }}
  command: sh / home / {{ k8s_node_admin_user }} / {{ k8s_cluster_name }} -join-command
k8s / common
The k8s / common role is used by both the master and worker nodes.

This role in turn makes use of Ansible's "meta" folder to indicate dependencies. A dependency is defined with the add_packages role that must install the packages indicated in the k8s_common_add_packages_names variable together with their repositories and public keys.

dependencies:
  - { role: add_packages,
    linux_add_packages_repositories: "{{k8s_common_add_packages_repositories}}" ,
    linux_add_packages_keys: "{{k8s_common_add_packages_keys}}" ,
    linux_add_packages_names: "{{k8s_common_add_packages_names}}" ,
    linux_remove_packages_names: "{{k8s_common_remove_packages_names}}"
    }
Definition of variables:

k8s_common_add_packages_keys:
- key: https : //download.docker.com/linux/ubuntu/gpg
- key: https : //packages.cloud.google.com/apt/doc/apt-key.gpg
k8s_common_add_packages_repositories:
- repo: "deb [arch = amd64] https://download.docker.com/linux/ubuntu {{ansible_distribution_release}} stable"
- repo: "deb https://apt.kubernetes.io/ kubernetes-xenial main" # k8s not available for Bionic (Ubuntu 18.04)
k8s_common_add_packages_names:
- name: apt-transport-https
- name: curl
- name: docker-ce
- name: docker-ce-cli
- name: containerd. io
- name: kubeadm
- name: kubelet
- name: kubectl
k8s_common_remove_packages_names:
- name:
k8s_common_admin_user:   "ubuntu"
k8s_common_admin_group: "ubuntu"

#The Ansible k8s / common playbook:

- name: Remove current swaps from fstab < br >   lineinfile: < br >     dest: / etc / fstab < br >     regexp: '^ / [S] + s + nones + swap < br >     state: absent
- name: Disable swap
  command: swapoff -a
  when: ansible_swaptotal_mb > 0
- name: Add k8s_common_admin_user user to docker group
  user:
    name: "{{k8s_common_admin_user}}"
    group: docker
- name: Check that docker service is started
  service:
        name: docker
        state: started
- name: Configure node-ip {{ k8s_node_public_ip }} at kubelet
  lineinfile:
    path: '/etc/systemd/system/kubelet.service.d/10-kubeadm.conf'
    line: 'Environment = "KUBELET_EXTRA_ARGS = - node-ip = {{k8s_node_public_ip}}"'
    regexp: 'KUBELET_EXTRA_ARGS ='
    insertafter: '[Service]'
    state: present
  notify:
    - restart kubelet
roles / add_packages
The add_packages role is specialized in installing and removing software packages.

#Steps:

Add public keys from repositories,
Add repositories to sources
Update the package cache (if repositories have been added),
Remove packages

Install packages
---
- name: Add new repositories keys
  apt_key:
    url = '{{item.key}}'
  with_items: "{{linux_add_packages_keys | default ([])}}"
  when: linux_add_packages_keys is defined and not ( linux_add_packages_keys is none or linux_add_packages_keys | trim == '' )
  register: aptnewkeys
- name: Add new repositories to sources
  apt_repository:
    repo = '{{item.repo}}'
  with_items: "{{linux_add_packages_repositories | default ([])}}"
  when: linux_add_packages_repositories is defined and not ( linux_add_packages_repositories is none or linux_add_packages_repositories | trim == '' )
- name: Force update cache if new keys added
  set_fact:
        linux_add_packages_cache_valid_time: 0
  when: aptnewkeys. changed
- name: Remove packages
  apt:
    name = {{ item. name }}
    state = absent
  with_items: "{{linux_remove_packages_names | default ([])}}"
  when: linux_remove_packages_names is defined and not ( linux_remove_packages_names is none or linux_remove_packages_names | trim == '' )
- name: Install packages
  apt:
    name = {{ item. name }}
    state = present
    update_cache = yes
    cache_valid_time = {{ linux_add_packages_cache_valid_time }}
  with_items: "{{linux_add_packages_names | default ([])}}"
  when: linux_add_packages_names is defined and not ( linux_add_packages_names is none or linux_add_packages_name
